\section{Задача III (декодування)}

Pозглянемо розв'язок останньої із задач -- задачі декодування. За заданою моделлю $\lambda=(\mu,A,B)$ i послiдовнiстю спостережень $y=(y_0, \ldots , y_T)_{y_t\in F}$ слід віднайти послiдовнiсть станiв $x=(x_0, \ldots , x_T)_{x_t\in E}$ прихованого ланцюга, яка максимiзує умовну ймовiрнiсть $P_\lambda(X=x \, |\, Y=y)$.

Еквiвалентним буде пошук послiдовностi, яка максимiзує ймовiрнiсть сумiсної появи ланцюжкiв: $P_\lambda(X=x,Y=y)$. Алгоритм, який дозволяє ефективно розв’я\-зати задачу декодування, називається алгоритмом
Вiтербi.

\subsection{Алгоритм Вітербі}

Введемо величини $\delta_t(x_t)$ -- ймовірності спостереження ланцюжка довжини $t$, використовуючи найкращий шлях, що закiнчується станом $x_t$ в момент часу $t:$
\[ \delta_t(x_t)=\max_{x_0,\ldots,x_{t-1}}P_\lambda(X_0=x_0,\ldots,X_t=x_t,Y_0=y_0,\ldots,Y_t=y_t) \]

При заданій моделі $\lambda=(\mu,A,B)$, покладаючи $\forall x_0\in E: \delta_0(x_0)=\mu_{x_0}B_{x_0y_0}$, усі вказані коефіцієнти можна визначити ітераційно: 
\[ \delta_{t+1}(x_{t+1})=B_{x_{t+1}y_{t+1}}\cdot\max_{x_t}\{\delta_t(x_t)A_{x_tx_{t+1}}\} \]

При цьому, щоб знайти оптимальний ланцюжок прихованих станiв, необхідно вiдстежувати аргумент, при якому досягається максимум $\delta_t(x_t)$ для кожного $t$ та $x_t$. Таким чином, алгоритм Вiтербi знаходження найбiльш ймовiрного ланцюжка прихованих станiв є таким:

\begin{enumerate}
    \item Ініціалізація:
    \begin{align*}
        &\forall x_0\in E: && \delta_0(x_0)=\mu_{x_0}B_{x_0y_0}, \ \psi_0(x_0)=0
    \end{align*}    
    \item Рекурентно обчислити коефіцієнти $\delta_t(x_t)$ та відповідні аргументи $\psi_t(x_t):$
    \begin{align*}
        &\forall t=\overline{0,T}, \ \forall x_{t+1} \in E: && \delta_{t+1}(x_{t+1})=B_{x_{t+1}y_{t+1}}\cdot\max_{x_t\in E}\{\delta_t(x_t)A_{x_tx_{t+1}}\} \\
        &\forall t=\overline{0,T}, \ \forall x_{t+1} \in E: && \psi_{t+1}(x_{t+1})=arg\max_{x_t\in E}\{\delta_t(x_t)A_{x_tx_{t+1}}\}
    \end{align*}
    \item Покласти зворотну точку відліку:
    \begin{align*}
        &\delta^*=\max_{x_T\in E}\{\delta_T(x_T)\} \\
        &\psi^*=arg\max_{x_T\in E}\{\delta_T(x_T)\}
    \end{align*}
    \item Визначити оптимальний ланцюжок станів (у зворотному порядку), починаючи з останнього $x_T^*=\psi^*:$
    \begin{align*}
        &\forall t=\overline{T-1,0}: && x_t^*=\psi_{t+1}(x_{t+1}^*)
    \end{align*}
\end{enumerate}

\subsection{Приклад: кмітливі учні}

Маючи в арсеналі інтсрумент для розв'язку задачі декодування, прослідкуємо за ще одним дослідженням учнів:

\vspace{0.2cm}
\begin{mdframed}[style=text box, topline=false, bottomline=false, rightmargin=0cm, leftmargin=0cm]
    \hspace{\tabsize}
    На жаль, результати задачі оцінювання показали учням, що, скоріше за все, наступного тижня у вечір проти четверга вони сидітимуть не на трибунах стадіону, а за робочими столами у своїх кімнатах, виконуючи домашнє завдання з математики.
    
    Зневірившись, у школярів виникає ідея безжальної авантюри: використати прийом психологічного тиску та просто-напросто спробувати вмовити (фактично, благати) викладача задати легке домашнє завдання у бажані для учнів дні. Проте, виконавши таку операцію під гарячу руку, себто під час поганого настрою викладача, наслідки можуть бути доволі невтішними.
    
    Відтак, отримавши в результаті задачі оцінювання на основі <<математичного портрету>> викладача найбільш імовірний ланцюжок заданих домашніх завдань наступного тижня, учні можуть спробувати спрогнозувати відповідну послідовність прихованих станів, тобто настроїв викладача. Тоді, завчасно звернувшись із пропозицією до учителя математики у найбільш сприйтливий для цього день, успіх буде гарантованим.
\end{mdframed}

\vspace{0.2cm}
Використовуючи алгоритм Вітербі, віднайдемо ланцюжок $x=(x_1,x_2,x_3,x_4,x_5)$ прихованих натроїв викладача за отриманим в результаті задачі оцінювання найбільш імовірним ланцюжком спотрежень заданого домашнього завдання протягом наступного тижня (висновки на стр. \pageref{P=0.25559}):
\[ y=(\text{\faSitemap},\text{\faSitemap},\text{\faSitemap},\text{\faSitemap},\text{\faSitemap}) \]

Наведемо дані стосовно учителя математики, тобто модель $\lambda:$

\vspace{0.4cm}
\begin{table}[H]
    \begin{minipage}[H]{0.35\linewidth}
        \begin{center}
            \begin{tabular}{c|ccc}
                & \faSmile[regular] & \faMeh[regular] & \faFrown[regular] \\
                \hline
                \faSmile[regular] & 0.2 & 0.3 & 0.5 \\
                \faMeh[regular] & 0.2 & 0.2 & 0.6 \\
                \faFrown[regular] & 0 & 0.2 & 0.8 \\
            \end{tabular}
        \end{center} \centering матриця $A$
    \end{minipage}
    \hfill
    \begin{minipage}[H]{0.35\linewidth}
        \begin{center}
            \begin{tabular}{c|ccc}
                & \text{\faMinus} & \text{\faRandom} & \text{\faSitemap} \\
                \hline
                \faSmile[regular] & 0.7 & 0.2 & 0.1 \\
                \faMeh[regular] & 0.3 & 0.4 & 0.3 \\
                \faFrown[regular] & 0 & 0.1 & 0.9 \\
            \end{tabular}
        \end{center} \centering матриця $B$
    \end{minipage}
    \hfill
    \begin{minipage}[H]{0.2\linewidth}
        \begin{center}
            \begin{tabular}{c|c}
                \faSmile[regular] & 0.05 \\
                \hline
                \faMeh[regular] & 0.2 \\
                \hline
                \faFrown[regular] & 0.75 \\
            \end{tabular}
        \end{center} \centering вектор $\mu$
    \end{minipage}
\end{table}

Наразі маюмо усю необхідну інформацію, аби запустити алгоритм декодування (спостережені типи завдань та приховані стани настроїв перекодовано номерами від $1$ до $3$):

\vspace{0.4cm}
\begin{lstlisting}[firstnumber=1, label = code: viterbi, caption = Алгоритм Вітербі]
    def viterbi(y,m,A,B):

        delta = [[0.0 for i in range(len(B))] for t in range(time)]
        psi = [[0 for i in range(len(B))] for t in range(time)]

        for t in range(time):
            for i in range(len(B)):
                if t == 0: 
                    delta[t][i] = m[i]*B[i][y[t]-1]
                else:
                    dA = []
                    for j in range(len(B)):
                        dA.append(delta[t-1][j]*A[j][i]*B[i][y[t]-1])
                    delta[t][i] = max(dA)
                    psi[t][i] = np.argmax(dA) + 1

        x = []
        delta_hat = max(delta[time-1])
        x.append(np.argmax(delta[time-1])+1)

        for t in range(time-2, -1, -1):
            x.insert(0, psi[t+1][x[0]-1])

        return x
\end{lstlisting}

\vspace{0.4cm}
В результаті отримуємо таку послідовність:
\[ x=\bigl( \text{\faFrown[regular]},\,\text{\faFrown[regular]},\,\text{\faFrown[regular]},\,\text{\faFrown[regular]},\,\text{\faFrown[regular]} \bigr) \]

Зрештою, це зовсім не дивно, зважаючи на заданий ланцюжок домашніх завдань. Можливо, учням варто задіяти класного керівника для врегулювання проблеми. Тоді задача декодування зведеться до прогнозу настрою їхнього куратора.

\subsection{Приклад: дешифрування тексту}

Наостанок, розв'яжемо задачу декодування вже розглянутого в одному з попередніх розділів зашифрованого тексту за допомогою алгоритму Вітербі. Сформулюємо задачу так: за відомими спостереженнями (тобто за набором літер зашифрованого тексту) віднайдемо прихований ланцюжок станів (для нас це буде розшифрований текст), використовуючи при цьому модель, навчену в результаті попереднього запуску алгоритму Баума-Велша (за методологією, наведеною на стр. \pageref{section: text decoding by Baum-Welch}).

Однак, через надвелику кількість літер у тексті (інакше кажучи, спостережуваних станів), алгоритм Вітербі слід модифікувати до алгоритму log-Вітербі.

\subsubsection{Алгоритм log-Вітербі}

У випадках, коли кількість спостережень є дуже великою, ітеративний пошук добутків, з яких формуються коефіцієнти $\delta_t(x_t)$, так чи інакше призведе до оперування з надмалими значеннями. Проте, використовуючи зростаючі властивості функції логарифма, усі максимуми, які беруть участь у формуванні величин $\delta_t(x_t)$, можна замінити рівносильними співвідношеннями: 
\[ \max\log f(x)=\log\max f(x) \]

Крім того, в алгоритмі log-Вітербі важливим є додатковий крок попередньої обробки, суть якого полягає у заміщенні всіх нульових елементів матриць та векторів наданої моделі $\lambda=(\mu,A,B)$ на найменші ненульові елементи, які сприймаються програматично. 

Наприклад, для мови \texttt{Python} пороговою точністю є значення $10^{-323}$. Це можна легко перевірити, порівнявши результати виконання відповідних команд:

\vspace{0.4cm}
\begin{table}[H]
    \begin{center}
        \begin{tabular}{||c|c||}
            \hline
            Команда & Результат \\
            \hline 
            \texttt{print(pow(10,-323))} & 1e-323 \\
            \hline 
            \texttt{print(pow(10,-324))} & 0.0 \\
            \hline
        \end{tabular}
    \end{center}
\end{table}

Отже, враховуючи усі зазначені зауваження, алгоритм log-Вітербі формулюватиметься таким чином:

\begin{enumerate}
    \item[0.] Попередня обробка:
    \begin{align*}
        \forall i\in E: \quad &\mu_i =
        \begin{cases}
            10^{-323}, & \mu_i = 0 \\
            \mu_i, & \mu_i \neq 0 \\
        \end{cases} \\ \\
        \forall i\in E,\, j\in F: \quad &A_{ij} =
        \begin{cases}
            10^{-323}, & A_{ij} = 0 \\
            A_{ij}, & A_{ij} \neq 0 \\
        \end{cases} \\ \\
        \forall i\in E,\, j\in F: \quad &B_{ij} =
        \begin{cases}
            10^{-323}, & B_{ij} = 0 \\
            B_{ij}, & B_{ij} \neq 0 \\
        \end{cases}
    \end{align*}
    \item Ініціалізація:
    \begin{align*}
        &\forall x_0\in E: && \delta_0(x_0)=\ln\mu_{x_0} + \ln B_{x_0y_0}, \ \psi_0(x_0)=0
    \end{align*}    
    \item Рекурентно обчислити коефіцієнти $\delta_t(x_t)$ та відповідні аргументи $\psi_t(x_t):$
    \begin{align*}
        &\forall t=\overline{0,T}, \ \forall x_{t+1} \in E: && \delta_{t+1}(x_{t+1})=\ln B_{x_{t+1}y_{t+1}}+ \max_{x_t\in E}\{\delta_t(x_t) + \ln A_{x_tx_{t+1}}\} \\
        &\forall t=\overline{0,T}, \ \forall x_{t+1} \in E: && \psi_{t+1}(x_{t+1})=arg\max_{x_t\in E}\{\delta_t(x_t)A_{x_tx_{t+1}}\}
    \end{align*}
    \item Покласти зворотну точку відліку:
    \begin{align*}
        &\delta^*=\max_{x_T\in E}\{\delta_T(x_T)\},\ \psi^*=arg\max_{x_T\in E}\{\delta_T(x_T)\}
    \end{align*}
    \item Визначити оптимальний ланцюжок станів (у зворотному порядку), починаючи з останнього $x_T^*=\psi^*:$
    \begin{align*}
        &\forall t=\overline{T-1,0}: && x_t^*=\psi_{t+1}(x_{t+1}^*)
    \end{align*}
\end{enumerate}

\subsubsection*{Результати}

Отримавши на вхід алгоритму log-Вітербі матрицю $A^0$, сформовану в результаті частотного аналізу оригінального тексту, переоцінену в ході роботи алгоритму Баума-Велша матрицю $B^*$ (88\% правильно вгаданих літер) та переоцінений вектор початкового розподілу $\mu^*$, маємо змогу порівняти отриманий розв'язок задачі декодування. Отже, оригінал тексту має вигляд:

\vspace{0.2cm}
\begin{mdframed}[style=text box]
    \hspace{\tabsize}\textsl{
    Проблема грошей набувала дедалі загрозливіших форм. Він був напередодні банкротства всього свого вбрання від кашкета до галош, що, послуживши йому півроку, починало виявляти ознаки страшного, хоч і природного занепаду, якого годі було вже приховати ретельним чищенням. Процес одягання, такий приємний йому колись, тепер у сущу муку обернувся, бо вранці наявніш, ніж будь-коли, показувалась руїна його білизни, крайнє зужиття черевиків та лихий блиск ліктів на піджаку, віщун майбутньої дірки.}
\end{mdframed}

\vspace{0.2cm}
В той час як результати роботи алгоритму є ось такими (пробіли вставлені виключно для простоти читання):

\vspace{0.2cm}
\begin{mdframed}[style=text box]
    \hspace{\tabsize}\textsl{
    проблеза грошей набувала дедалі загрозливіших щорз він був напередодні банкровства всього свого вбрання від каємета до галоє мо постуживши йому півроку починало виявляти ознаки страєщого гоч і природного занепаду якого годі було вже приховати ретельним чименням процес одягання такий приємний йому колись тепер у суму муку обернувся бо вранці наявніш ній будь коли показувалась ружна його білизни крайнє зужиття черевиків та лихий блиск ліктів на піджаку вімун зайбутньої дірки}
\end{mdframed}